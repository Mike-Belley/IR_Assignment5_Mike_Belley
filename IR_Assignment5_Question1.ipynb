{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "nBxUuh83o7mu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXehvKhjZqGG",
        "outputId": "e875608c-7dc9-4596-ed4d-fa3ee6cda488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus.reader.tagged import word_tokenize\n",
        "from scipy import spatial\n",
        "\n",
        "from post_parser_record import PostParserRecord\n",
        "post_reader = PostParserRecord(\"Posts_Coffee.xml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "0DhyXAkFpAUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing to make sure I can get the training set in the correct format\n",
        "question_titles_test = []\n",
        "question_titles_test.append([\"this\", \"is\", \"a\", \"test\"])\n",
        "question_titles_test.append([\"hello\", \"world\"])\n",
        "question_titles_test.append(word_tokenize(\"I am currently, testing the tokenizer\"))\n",
        "\n",
        "question_titles_test\n",
        "# common_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1POe_fPZ_HR",
        "outputId": "9b9717c3-85a4-4728-c07b-0dffa777be4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['this', 'is', 'a', 'test'],\n",
              " ['hello', 'world'],\n",
              " ['I', 'am', 'currently', ',', 'testing', 'the', 'tokenizer']]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initiaize and train the word2vec model"
      ],
      "metadata": {
        "id": "5sCiQ5sCoV5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize a list that will store all the question titles\n",
        "question_titles = []\n",
        "\n",
        "# go thru all the questions, tokenize the title, and add it to the list\n",
        "for question_id in post_reader.map_questions:\n",
        "  question = post_reader.map_questions[question_id]\n",
        "  question_titles.append(word_tokenize(question.title))"
      ],
      "metadata": {
        "id": "MV_ykdSCbY7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the word2vec model\n",
        "model = Word2Vec(sentences=question_titles, window=5, min_count=1, workers=4)\n",
        "model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu1qrT68dJ5u",
        "outputId": "06516d09-22ae-4619-b6ca-17c71e79b4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the word2vec model with the question titles\n",
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "model.train(question_titles, total_examples=len(question_titles), epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLdgydRGcfTz",
        "outputId": "17077e7e-eef4-4bd2-ae6c-ba08a0df956d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95218, 137140)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "w8TTIIVipFRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# testing vector adding and dividing and such\n",
        "vector1 = model.wv['caffeine']\n",
        "vector2 = model.wv['tool']\n",
        "vector3 = vector1 + vector2\n",
        "print(vector3 / 2)\n",
        "print(1 - spatial.distance.cosine(vector1, vector2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkFp_FAPd749",
        "outputId": "bbb9e141-0338-4c82-97fc-4dc68edf22d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.76101387e-01  1.73281178e-01 -5.34324467e-01  2.20231235e-01\n",
            "  1.88666880e-01 -4.25964519e-02  1.45008668e-01 -4.84522730e-01\n",
            " -1.56262755e-01 -8.76702890e-02 -2.76686698e-01 -4.42019552e-01\n",
            "  3.17836478e-02  1.62685721e-03 -1.54981360e-01  2.46341735e-01\n",
            "  1.98340714e-02  2.52772689e-01  7.99055770e-02  1.34656399e-01\n",
            "  1.46367162e-01 -7.20187128e-02  1.09330401e-01  5.03382348e-02\n",
            "  3.73441309e-01  2.68004090e-01  4.13864553e-01 -2.08852828e-01\n",
            " -2.92208344e-01  3.87656838e-01 -5.43877520e-02 -5.13146259e-02\n",
            "  7.32969418e-02  2.29930431e-01 -1.14152461e-01  4.86652330e-02\n",
            " -1.27297223e-01  3.28291357e-01  1.51310498e-02 -1.49643183e-01\n",
            " -1.87796071e-01 -3.42664689e-01 -1.25121042e-01  1.56036705e-01\n",
            " -1.19946383e-01 -3.36952716e-01 -7.23981708e-02  4.06094342e-01\n",
            " -3.81843358e-01 -2.65016854e-01  2.73881763e-01 -1.53535903e-01\n",
            " -9.72105041e-02 -9.63442475e-02  1.39155209e-01 -1.50697052e-01\n",
            " -1.14740498e-01  1.15297966e-01 -6.28181621e-02  3.22430849e-01\n",
            "  1.82407558e-01  8.05336144e-03 -1.52371183e-01 -2.71925509e-01\n",
            " -1.68852240e-01 -1.47902044e-02  3.79617102e-02 -8.16423669e-02\n",
            "  3.71334180e-02  1.34278625e-01  1.96887270e-01 -4.66216996e-04\n",
            " -1.85471833e-01  2.15015024e-01 -3.49558681e-01  2.34682821e-02\n",
            " -2.34175414e-01  1.83673352e-01 -5.79268523e-02  3.49179864e-01\n",
            "  1.66144162e-01  8.53715464e-03 -1.38541415e-01  7.99690485e-02\n",
            "  2.27772161e-01 -2.26142555e-01 -1.57367930e-01 -1.26897931e-01\n",
            " -7.13753775e-02  6.63043931e-02 -2.27489606e-01  1.35898128e-01\n",
            " -3.98420766e-02 -2.59319782e-01 -2.98402589e-02  1.01084210e-01\n",
            "  3.94239485e-01  2.50918627e-01 -2.38667000e-02  8.86182934e-02]\n",
            "0.9959811568260193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting and Storing the Vectors of Questions"
      ],
      "metadata": {
        "id": "TnbivOOhobnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize a dicitonary that will store all the vectors for the questions\n",
        "question_vectors = {}\n",
        "\n",
        "for question_id in post_reader.map_questions:\n",
        "  question = post_reader.map_questions[question_id]\n",
        "  title = word_tokenize(question.title)\n",
        "\n",
        "  # initialize the vector for the question\n",
        "  vector = model.wv[title[0]]\n",
        "  vector = vector - vector\n",
        "\n",
        "  # go thru all the words in the question and add their vectors\n",
        "  for word in title:\n",
        "    vector = vector + model.wv[word]\n",
        "\n",
        "  # find the average for all the words\n",
        "  vector = vector / len(title)\n",
        "\n",
        "  # add the question to the dictionary of vectors\n",
        "  question_vectors[question_id] = vector.copy()"
      ],
      "metadata": {
        "id": "VqHOCNI1gX-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Cosine Similarity Based off of a Query"
      ],
      "metadata": {
        "id": "nzEE53baomZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store a query to compare in a string and find the vector representation of it\n",
        "query = \"When does coffee go off?\"\n",
        "query_tokens = word_tokenize(query)\n",
        "query_vector = model.wv[query_tokens[0]]\n",
        "query_vector = query_vector - query_vector\n",
        "for word in query_tokens:\n",
        "  query_vector = query_vector + model.wv[word]\n",
        "query_vector = query_vector / len(title)"
      ],
      "metadata": {
        "id": "KL80q89riabp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize a dict which will store the cosine similarity between the query and all titles by id\n",
        "query_cosine = {}\n",
        "\n",
        "# iterate thru all the question vectors\n",
        "for key in question_vectors:\n",
        "  # calculate and store cosine similary value for the id\n",
        "  query_cosine[key] = 1 - spatial.distance.cosine(query_vector, question_vectors[key])"
      ],
      "metadata": {
        "id": "mFJFElxajqYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "itipsQOXosuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the cosine dict by value and print top 5\n",
        "cosine_sorted = dict(sorted(query_cosine.items(), reverse=True, key=lambda item: item[1]))\n",
        "for x in list(cosine_sorted)[0:5]:\n",
        "    print (\"docid {}, value {} \".format(x,  cosine_sorted[x]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pSliSAbmHMQ",
        "outputId": "16308818-52e2-4bdd-ab11-9f86c9e1b70c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "docid 123, value 1 \n",
            "docid 473, value 0.9999468922615051 \n",
            "docid 3582, value 0.9999434947967529 \n",
            "docid 4358, value 0.9999416470527649 \n",
            "docid 5713, value 0.999941349029541 \n"
          ]
        }
      ]
    }
  ]
}